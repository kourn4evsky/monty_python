{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание №1\n",
    "\n",
    "#### Скачайте текст *\"Литературных анекдотов\"*. Напишите функцию, которая будет читать файл, лемматизировать текст с помощью pymystem3 и записывать результат в новый файл. У функции должно бы два аргумента: путь к исходному файлу и путь к файлу с лемматизированным текстом. Вызов функции тоже должен быть прописан в решении.\n",
    "\n",
    "Файл текста будет находиться в одной директории с *.ipynb* файлом домашнего задания."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from pymystem3 import Mystem # эти библиотеки понадобятся для первого задания"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmachine(text, lext): #создается функция с двумя аргументами\n",
    "    with open(text, 'r', encoding='utf-8') as f: #открывается и читается исходноый файл\n",
    "        dirtyjokes = f.read()\n",
    "        f.closed\n",
    "    m = Mystem(mystem_bin=\"C:/Users/Леня/Desktop/python/mystem\") #без пути под 32'й семеркой последняя версия Mystem не работает\n",
    "    lemmas = m.lemmatize(dirtyjokes) #лемматизируется текст\n",
    "    line = ''.join(lemmas) #текст сводится в одну строку\n",
    "    with open(lext, 'w', encoding='utf-8') as f: #создается новый файл для записи\n",
    "        f.write(line)\n",
    "lemmachine('C:/Users/Леня/Desktop/python/python-dh-hw/literary_anecdotes.txt','C:/Users/Леня/Desktop/python/python-dh-hw/lemmaz.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание №2\n",
    "\n",
    "#### Очистите лемматизированный текст от стоп-слов и посчитайте ipm для оставшихся. Выведите 20 самых частотных по этому параметру слов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter #добавляется Counter для подсчета частотности слов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('пушкин', 35822.7079538555), ('толстой', 20036.429872495446), ('гоголь', 18822.100789313903), ('однажды', 17607.771706132364), ('лев', 15179.113539769278), ('любить', 12143.290831815422), ('достоевский', 12143.290831815422), ('тургенев', 9714.632665452338), ('ребенок', 9107.468123861567), ('царствие', 9107.468123861567), ('небесный', 9107.468123861567), ('окно', 7285.974499089253), ('тверской', 7285.974499089253), ('бульвар', 7285.974499089253), ('приходить', 7285.974499089253), ('лермонтов', 7285.974499089253), ('федор', 6678.809957498483), ('михайлович', 6678.809957498483), ('идти', 6071.645415907711), ('герцен', 6071.645415907711)]\n"
     ]
    }
   ],
   "source": [
    "with open('C:/Users/Леня/Desktop/python/python-dh-hw/rus_stopwords.txt', 'r', encoding='utf-8') as stop: #открывается заранее скачанный файл со стоп-словами\n",
    "    stops = stop.read()\n",
    "    stop.closed\n",
    "stops = stops.split('\\n')\n",
    "with open('lemmaz.txt', 'r', encoding='utf-8') as f: #открывается и читается лемматизированный файл\n",
    "        jokes = f.read()\n",
    "        f.closed\n",
    "punct = \"!\\\"#$%&'()*+,./:;<=>?@[\\]^_`{|}~„“«»†*—/\\-—\" #убирается пунктуация и текст собирается в строку\n",
    "jokes = [word.strip(punct) for word in jokes.split()] \n",
    "cleanjokes = ' '.join(jokes) \n",
    "boringjokes = [joke for joke in cleanjokes.split() if joke not in stops] #создается новый список без стоп-слов\n",
    "counts = Counter(boringjokes)\n",
    "ipms = {}\n",
    "for key, value in counts.items(): #производится подсчет ipm\n",
    "    ipm = value / len(boringjokes) * 1000000\n",
    "    ipms[key] = ipm\n",
    "sorted_ipms = sorted(ipms.items(), key=lambda x: x[1], reverse=True) \n",
    "print(sorted_ipms[:20]) #выводится 20 наиболее частотных слов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание №3\n",
    "#### 1. Сделайте полный морфологический разбор исходного текста. Напишите регулярное выражение, которое будет извлекать из тега только часть речи. Пройдитесь циклом по списку с разборами, который выдал pymystem3, извлекая из каждого разбора форму слова и его часть речи и записывая их в новый словарь (форма -- ключ, часть речи -- значение). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('C:/Users/Леня/Desktop/python/python-dh-hw/literary_anecdotes.txt', 'r', encoding='utf-8') as f: #открывается и читается лемматизированный файл\n",
    "        dirtyjokes = f.read()\n",
    "        f.closed\n",
    "morfe = m.analyze(dirtyjokes) #проводится общий морфологический анализ\n",
    "speech = {} #создается словарь под \n",
    "smartspeech = {}\n",
    "final = re.compile('[A-Z]+')\n",
    "for word in morfe:\n",
    "    try:\n",
    "        form = word['text']\n",
    "        grammar = word['analysis'][0]['gr']\n",
    "        speech[form] = grammar\n",
    "    except (KeyError, IndexError):  \n",
    "        pass          # обходим возможные ошибки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Посчитайте абсолютную частоту для всех частей речи, а затем относительную частоту (абсолютная частота / длина текста в словах). Это отдельная подзадача, т.е. считать нужно не по словарю."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
